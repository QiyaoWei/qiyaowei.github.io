## Open Research Questions
Honestly, a lot of the presented themes I highlighted throughout this article are probably still considered "open research questions". The following list is not comprehensive or uniformly distributed across each of the topics, and is just a list of research directions I became interested in after reading through the abstracts. The order is completely arbitrary, although I tried to somewhat categorize them. Some of these things might later be proven to be impossible. Some might already be half-solven, and some might actually already be solved without me knowing. I also tried to focus mainly on questions that can be answered without the use of heavy compute.

1. LLM outputs are **not consistent**, but it's also unclear where and why these failure modes occur. I'm interested in rigorous analysis on *basic factual consistency*, or even a metric for defining consistency. The end goal being 1) a method like instruction-tuning for consistent generations with high probability or 2) controlled generation to ensure consistency.
2. Continuing <d-cite key="wu2023read"></d-cite> but actually applying this language-based reward-shaping paradigm to a problem dependent on external text and manuals to solve. Like player-vs-player strategy games. It is far more interesting for games with adversarial behavior, where learning a policy requires an understanding of the game.
3. Fairness and bias is **largely understudied** in large language models. People love to churn out techniques and algorithms with extra overhead to tune out bad data during training, but it would be so much easier to come up with algorithms or metrics that clean or augment data prior to training. This is an extremely low-hanging fruit IMO but I guess it's not as interesting so it's a slow process.
4.
5. 