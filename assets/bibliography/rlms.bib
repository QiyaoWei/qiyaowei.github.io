@inproceedings{wang2024executable,
    title={Executable Code Actions Elicit Better LLM Agents},
    author={Xingyao Wang and Yangyi Chen and Lifan Yuan and Yizhe Zhang and Yunzhu Li and Hao Peng and Heng Ji},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=jJ9BoXAfFa},
    note={codeact},
}

@misc{chen2025browsecompplusfairtransparentevaluation,
      title={BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent}, 
      author={Zijian Chen and Xueguang Ma and Shengyao Zhuang and Ping Nie and Kai Zou and Andrew Liu and Joshua Green and Kshama Patel and Ruoxi Meng and Mingyi Su and Sahel Sharifymoghaddam and Yanxi Li and Haoran Hong and Xinyu Shi and Xuye Liu and Nandan Thakur and Crystina Zhang and Luyu Gao and Wenhu Chen and Jimmy Lin},
      year={2025},
      eprint={2508.06600},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2508.06600}, 
}

@misc{wei2025browsecompsimplechallengingbenchmark,
    title={BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents},
    author={Jason Wei and Zhiqing Sun and Spencer Papay and Scott McKinney and Jeffrey Han and Isa Fulford and Hyung Won Chung and Alex Tachard Passos and William Fedus and Amelia Glaese},
    year={2025},
    eprint={2504.12516},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2504.12516},
}

@inproceedings{anonymous2025oolong,
    title={Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities},
    author={Anonymous},
    booktitle={Submitted to The Fourteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=lrDr6dmXOX},
    note={under review}
}

@misc{LoCoDiffBench2025,
  title        = {LoCoDiff Benchmark},
  author       = {MentatAI and AbanteAI},
  howpublished = {\url{https://abanteai.github.io/LoCoDiff-bench/}},
  year         = {2025},
}

@misc{packer2024memgptllmsoperatingsystems,
      title={MemGPT: Towards LLMs as Operating Systems}, 
      author={Charles Packer and Sarah Wooders and Kevin Lin and Vivian Fang and Shishir G. Patil and Ion Stoica and Joseph E. Gonzalez},
      year={2024},
      eprint={2310.08560},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2310.08560}, 
}

@misc{jolicoeurmartineau2025morerecursivereasoningtiny,
      title={Less is More: Recursive Reasoning with Tiny Networks}, 
      author={Alexia Jolicoeur-Martineau},
      year={2025},
      eprint={2510.04871},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2510.04871}, 
}


@misc{chen2023walkingmemorymazecontext,
      title={Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading}, 
      author={Howard Chen and Ramakanth Pasunuru and Jason Weston and Asli Celikyilmaz},
      year={2023},
      eprint={2310.05029},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.05029}, 
}

@misc{simonds2025ladderselfimprovingllmsrecursive,
      title={LADDER: Self-Improving LLMs Through Recursive Problem Decomposition}, 
      author={Toby Simonds and Akira Yoshiyama},
      year={2025},
      eprint={2503.00735},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2503.00735}, 
}

@inproceedings{schroeder-etal-2025-thread,
    title = {THREAD: Thinking Deeper with Recursive Spawning},
    author = {Schroeder, Philip  and
      Morgan, Nathaniel W.  and
      Luo, Hongyin  and
      Glass, James R.},
    editor = {Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu},
    booktitle = {Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
    month = apr,
    year = {2025},
    address = {Albuquerque, New Mexico},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2025.naacl-long.427/},
    doi = {10.18653/v1/2025.naacl-long.427},
    pages = {8418--8442},
    ISBN = {979-8-89176-189-6},
    abstract = {Large language models (LLMs) have shown impressive capabilities across diverse settings, but still struggle as the length and complexity of the context increases. To address this challenge, we propose Thinking Recursively and Dynamically (ThReaD). THREAD frames model generation as a thread of execution that, based on the context, can run to completion or dynamically spawn new threads. By spawning, threads can offload work (e.g., thinking, retrieving information) to child threads, which only return tokens needed for the parent thread to do its work. We apply THREAD in the settings of LLM task solving and question answering, where the dynamic threading allows the model to recursively decompose the given task or question into progressively simpler sub-problems that can be solved by separate child threads. We test THREAD, implemented using a few-shot learning approach, on diverse benchmarks for agent tasks and data-grounded question answering. THREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on these benchmarks, including ALFWorld, TextCraft, and WebShop, along with two new benchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREAD outperforms existing frameworks by 10{\%} to 50{\%} absolute points with smaller models, including Llama-3-8b and CodeLlama-7b.}
}